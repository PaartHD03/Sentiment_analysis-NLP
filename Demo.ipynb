{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e95cd73-0070-492b-801c-57d56dceaae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# Initialize the list to store item data\n",
    "items = []\n",
    "\n",
    "# Loop through pages until 200 items are collected\n",
    "page = 1\n",
    "while len(items) < 200:\n",
    "    url = f\"https://www.noon.com/uae-en/sports-and-outdoors/exercise-and-fitness/yoga-16328/{page}\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'lxml')\n",
    "\n",
    "    # Find all product divs\n",
    "    product_divs = soup.find_all('div', '_2kHMtA')\n",
    "\n",
    "    for product in product_divs:\n",
    "        if len(items) >= 200:  # Stop if 200 items are collected\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            # Extract fields\n",
    "            datetime = product.find('span', class_='date-class').text if product.find('span', class_='date-class') else \"N/A\"\n",
    "            sku = product.get('data-sku', \"N/A\")\n",
    "            name = product.find('div', '_4rR01T').text if product.find('div', '_4rR01T') else \"N/A\"\n",
    "            brand = product.find('div', class_='brand-class').text if product.find('div', class_='brand-class') else \"N/A\"\n",
    "            average_rating = product.find('div', '_3LWZlK').text if product.find('div', '_3LWZlK') else \"N/A\"\n",
    "            rating_count = product.find('span', class_='rating-count-class').text if product.find('span', class_='rating-count-class') else \"N/A\"\n",
    "            old_price = product.find('div', class_='old-price-class').text.replace('â‚¹', '').replace(',', '') if product.find('div', class_='old-price-class') else \"N/A\"\n",
    "            new_price = product.find('div', '_30jeq3 _1_WHN1').text.replace('â‚¹', '').replace(',', '') if product.find('div', '_30jeq3 _1_WHN1') else \"N/A\"\n",
    "            rank = product.find('span', class_='rank-class').text if product.find('span', class_='rank-class') else \"N/A\"\n",
    "            item_link = product.find('a', href=True)['href'] if product.find('a', href=True) else \"N/A\"\n",
    "\n",
    "            # Append to items list\n",
    "            items.append({\n",
    "                'datetime': datetime,\n",
    "                'sku': sku,\n",
    "                'name': name,\n",
    "                'brand': brand,\n",
    "                'average_rating': average_rating,\n",
    "                'rating_count': rating_count,\n",
    "                'old_price': old_price,\n",
    "                'new_price': new_price,\n",
    "                'rank': rank,\n",
    "                'item_link': f\"https://www.noon.com{item_link}\"\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing product: {e}\")\n",
    "\n",
    "    print(f\"Page {page} processed, total items collected: {len(items)}\")\n",
    "    page += 1\n",
    "    time.sleep(2)  # Add delay to avoid overwhelming the server\n",
    "\n",
    "# Save data to a CSV file\n",
    "csv_file = \"noon_items.csv\"\n",
    "fieldnames = ['datetime', 'sku', 'name', 'brand', 'average_rating', 'rating_count', 'old_price', 'new_price', 'rank', 'item_link']\n",
    "\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(items)\n",
    "\n",
    "print(f\"Data saved to {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080f395e-3d13-4f18-8c18-7042d6cacde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "# Initialize list for storing product details\n",
    "products = []\n",
    "\n",
    "# Sample URL (update with your URL)\n",
    "url = \"https://www.noon.com/uae-en/sports-and-outdoors/exercise-and-fitness/yoga-16328/\"\n",
    "\n",
    "# Fetch and parse the page\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Locate all product containers\n",
    "product_containers = soup.find_all('div', class_='sc-57fe1f38-1')\n",
    "\n",
    "for product in product_containers:\n",
    "    try:\n",
    "        # Extract product details\n",
    "        name = product.find('div', {'data-qa': 'product-name'}).get('title', 'N/A')\n",
    "        price = product.find('strong', class_='amount').text if product.find('strong', class_='amount') else 'N/A'\n",
    "        old_price = product.find('span', class_='oldPrice').text if product.find('span', class_='oldPrice') else 'N/A'\n",
    "        discount = product.find('span', class_='discount').text if product.find('span', class_='discount') else 'N/A'\n",
    "        image_url = product.find('div', class_='sc-d8caf424-2').img['src'] if product.find('div', class_='sc-d8caf424-2') else 'N/A'\n",
    "        delivery_info = product.find('div', class_='sc-4d61bf64-3').text.strip() if product.find('div', class_='sc-4d61bf64-3') else 'N/A'\n",
    "        noon_express = product.find('div', {'data-qa': 'product-noon-express'}).text.strip() if product.find('div', {'data-qa': 'product-noon-express'}) else 'N/A'\n",
    "        product_link = product.find('a', href=True)['href'] if product.find('a', href=True) else 'N/A'\n",
    "\n",
    "        # Append details to list\n",
    "        products.append({\n",
    "            'Name': name,\n",
    "            'Price': price,\n",
    "            'Old Price': old_price,\n",
    "            'Discount': discount,\n",
    "            'Image URL': image_url,\n",
    "            'Delivery Info': delivery_info,\n",
    "            'Noon Express': noon_express,\n",
    "            'Product Link': f\"https://www.noon.com{product_link}\"\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting product: {e}\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = \"products.csv\"\n",
    "fieldnames = ['Name', 'Price', 'Old Price', 'Discount', 'Image URL', 'Delivery Info', 'Noon Express', 'Product Link']\n",
    "\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(products)\n",
    "\n",
    "print(f\"Data saved to {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949dfbd6-d09e-4c83-9d1b-b359f07b5ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Preprocess the tweet\n",
    "def preprocess_tweet(tweet):\n",
    "    tweet_words = []\n",
    "    for word in tweet.split(' '):\n",
    "        if word.startswith('@') and len(word) > 1:\n",
    "            word = '@user'\n",
    "        elif word.startswith('http'):\n",
    "            word = 'http'\n",
    "        tweet_words.append(word)\n",
    "    return ' '.join(tweet_words)\n",
    "\n",
    "# Load model and tokenizer\n",
    "roberta = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(roberta)\n",
    "tokenizer = AutoTokenizer.from_pretrained(roberta)\n",
    "\n",
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "def sentiment_analysis():\n",
    "    # Get user input\n",
    "    tweet = input(\"Enter a tweet or sentence: \")\n",
    "\n",
    "    # Preprocess the input\n",
    "    tweet_proc = preprocess_tweet(tweet)\n",
    "\n",
    "    # Perform sentiment analysis\n",
    "    encoded_tweet = tokenizer(tweet_proc, return_tensors='pt')\n",
    "    output = model(**encoded_tweet)\n",
    "\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "\n",
    "    # Print sentiment scores\n",
    "    print(\"\\nSentiment Analysis Results:\")\n",
    "    for i in range(len(scores)):\n",
    "        l = labels[i]\n",
    "        s = scores[i]\n",
    "        print(f\"{l}: {s:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sentiment_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30ea865-c2f6-480a-ba96-2c4e62ea443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "\n",
    "tweet = 'yohoho! my name is Paarth and I am happy ðŸ˜‰'\n",
    "\n",
    "# precprcess tweet\n",
    "tweet_words = []\n",
    "\n",
    "for word in tweet.split(' '):\n",
    "    if word.startswith('@') and len(word) > 1:\n",
    "        word = '@user'\n",
    "    \n",
    "    elif word.startswith('http'):\n",
    "        word = \"http\"\n",
    "    tweet_words.append(word)\n",
    "\n",
    "tweet_proc = \" \".join(tweet_words)\n",
    "\n",
    "# load model and tokenizer\n",
    "roberta = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(roberta)\n",
    "tokenizer = AutoTokenizer.from_pretrained(roberta)\n",
    "\n",
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# sentiment analysis\n",
    "encoded_tweet = tokenizer(tweet_proc, return_tensors='pt')\n",
    "# output = model(encoded_tweet['input_ids'], encoded_tweet['attention_mask'])\n",
    "output = model(**encoded_tweet)\n",
    "\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "for i in range(len(scores)):\n",
    "    \n",
    "    l = labels[i]\n",
    "    s = scores[i]\n",
    "    print(l,s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
